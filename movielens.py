# -*- coding: utf-8 -*-
"""MovieLens

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1alo4zYco14XG8gpPv1GDhCxQh1Qaps4w
"""

!pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d rounakbanik/the-movies-dataset

! unzip the-movies-dataset.zip

import pandas as pd

rating = pd.read_csv('ratings_small.csv')

rating.head()

rating = rating.iloc[:,0:3]

rating.head()

"""# Using MovieLens100K instead of MovieLens2M because my RAM Crashes on 2M points"""

!pip3 install surprise

import pandas as pd
from surprise import SVD, similarities
from surprise import Dataset, accuracy
from surprise import NormalPredictor
from surprise import Reader
from surprise.prediction_algorithms.knns import KNNWithMeans
from surprise.model_selection import cross_validate, train_test_split, KFold

from surprise import BaselineOnly

# A reader is still needed but only the rating_scale param is requiered.
reader = Reader(rating_scale=(1, 5))

# The columns must correspond to user id, item id and ratings (in that order).
data = Dataset.load_from_df(rating[['userId', 'movieId', 'rating']], reader)

"""The famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize.
When baselines are not used, this is equivalent to Probabilistic Matrix Factorization 
[salakhutdinov2008a] (see note below)..

# 3 C
"""

# 3 c. [TYPE-1] Average MAE and RMSE for Probabilistic Matrix Factorization using 5 - Fold CF
algo = SVD()
results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

print("MAE on Test Set using 5 fold CV", results['test_mae'].mean())
print("RMSE on Test Set using 5 fold CV", results['test_rmse'].mean())

# 3 c. [TYPE-2] Average MAE and RMSE for Item Base Collaborative Filtering using 5 - Fold CF
sim_options = {
    "user_based": False,
}

knn_m = KNNWithMeans(sim_options=sim_options)
scores = cross_validate(knn_m, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

mean_mae = scores['test_mae'].mean()
mean_rsme = scores['test_rmse'].mean()

print(f'Average MAE: {mean_mae}')
print(f'Average RMSE: {mean_rsme}')

# 3 c. [TYPE-3] Average MAE and RMSE for User Base Collaborative Filtering using 5 - Fold CF
sim_options = {
    "user_based": True,
}

knn_m = KNNWithMeans(sim_options=sim_options)
scores = cross_validate(knn_m, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

mean_mae = scores['test_mae'].mean()
mean_rsme = scores['test_rmse'].mean()

print(f'Average MAE: {mean_mae}')
print(f'Average RMSE: {mean_rsme}')

"""Report : <br>
Item Based Collaborative Filtering was better than User Based CF and PMF.<br>
MAE and RMSE Errors were less for Item-Based CF

## 3 E Effect of Cosine, MSD, Pearson Similarities on Collaborative Filtering
"""

# 3 e. [TYPE-1] Comparing Cosine, MSD, Pearson Similarities on Item Based CF
similarity_names = ['cosine','msd','pearson']
mean_mae_item = []
mean_rmse_item = []
for name in similarity_names:
  sim_options = {
    "user_based": False,
    "name": name
  }

  knn_m = KNNWithMeans(sim_options=sim_options)
  scores = cross_validate(knn_m, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

  mean_mae_item.append(scores['test_mae'].mean())
  mean_rmse_item.append(scores['test_rmse'].mean())

print(f'Similarity Measure: {similarity_names}')
print(f'Average MAE: {mean_mae_item}')
print(f'Average RMSE: {mean_rmse_item}')

# 3 e. [TYPE-2] Comparing Cosine, MSD, Pearson Similarities on User Based CF
similarity_names = ['cosine','msd','pearson']
mean_mae_user = []
mean_rmse_user = []
for name in similarity_names:
  sim_options = {
    "user_based": True,
    "name": name
  }

  knn_m = KNNWithMeans(sim_options=sim_options)
  scores = cross_validate(knn_m, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

  mean_mae_user.append(scores['test_mae'].mean())
  mean_rmse_user.append(scores['test_rmse'].mean())

print(f'Similarity Measure: {similarity_names}')
print(f'Average MAE: {mean_mae_user}')
print(f'Average RMSE: {mean_rmse_user}')

import matplotlib.pyplot as plt
import numpy as np

ind = np.arange(len(similarity_names))
plt.figure(figsize=(10,5))
plt.bar(ind, mean_mae_item, 0.5, label='MAE')
plt.bar(ind + 0.5, mean_rmse_item, 0.5, label='RMSE')


plt.xlabel('measures')
plt.ylabel('scoring')


plt.legend(loc='best')
plt.show()

ifig=1
labels = ['USER-BASED COLLAB. FILTERING', 'ITEM-BASED COLLAB. FILTERING']
x = np.arange(0, len(labels) * 2.5, 2.5)
width = 0.5
plt.figure(ifig)
fig, ax = plt.subplots(figsize=(18,5))
for i in range(len(similarity_names)):
    ax.bar(x - (width * len(similarity_names)) / 2 + i * width, [mean_mae_user[i], mean_mae_item[i]], width, label=similarity_names[i])
plt.xticks(x - width / 2, labels)
plt.title('ITEM AND USER BASED COLLABORATIVE FILTERING FOR MAE')
plt.ylabel('mae')
plt.grid(axis='y')
plt.legend()
plt.show()

"""Impact of K on Collaborative Filtering"""

#3f)
ks = np.arange(1, 20, 1)


ub_mae = []
ub_rmse = []

for k in ks: 
    
    sim_options = {
    "user_based": True, 
    }
    
    
    knn_m = KNNWithMeans(k, sim_options=sim_options)
    scores = cross_validate(knn_m, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)
    
    
    mean_mae = scores['test_mae'].mean()
    mean_rsme = scores['test_rmse'].mean()
    
   
    ub_mae.append(mean_mae)
    ub_rmse.append(mean_rsme)

ib_mae = []
ib_rmse = []

for k in ks: 
    sim_options = {
    "user_based": False,  
    }
    
    knn_m = KNNWithMeans(k, sim_options=sim_options)
    scores = cross_validate(knn_m, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)
    
    mean_mae = scores['test_mae'].mean()
    mean_rsme = scores['test_rmse'].mean()
    
    ib_mae.append(mean_mae)
    ib_rmse.append(mean_rsme)

plt.figure(figsize=(10,5))
plt.plot(ks, ub_rmse)
plt.title('NEIGHBOURS FOR RMSE ON USER-BASED COLLAB. FILTERING')
plt.xlabel('neighbors')
plt.ylabel('RMSE')

plt.show()

plt.figure(figsize=(10,5))
plt.plot(ks, ib_rmse)
plt.title('NEIGHBOURS FOR RMSE ON ITEM-BASED COLLAB. FILTERING')
plt.xlabel('neighbors')
plt.ylabel('RMSE')

plt.show()

plt.figure(figsize=(10,5))
plt.plot(ks, ub_mae)
plt.title('NEIGHBOURS FOR MAE ON USER-BASED COLLAB. FILTERING')
plt.xlabel('neighbors')
plt.ylabel('MAE')

plt.show()

plt.figure(figsize=(10,5))
plt.plot(ks, ib_mae)
plt.title('NEIGHBOURS FOR RMSE ON ITEM-BASED COLLAB. FILTERING')
plt.xlabel('neighbors')
plt.ylabel('MAE')


plt.show()

#3g)
print('USER-BASED COLLAB. FILTERING - MAE')
print('Best K: ', ks[np.argmin(ub_mae)])
print('Best K MAE: ', np.min(ub_mae))

print('\nUSER-BASED COLLAB. FILTERING - RMSE')
print('Best K: ', ks[np.argmin(ub_rmse)])
print('Best K RMSE: ', np.min(ub_rmse))

print('\nITEM-BASED COLLAB. FILTERING - MAE')
print('Best K: ', ks[np.argmin(ib_mae)])
print('Best K MAE: ', np.min(ib_mae))

print('\nITEM-BASED COLLAB. FILTERING - RMSE')
print('Best K: ', ks[np.argmin(ib_rmse)])
print('Best K RMSE: ', np.min(ib_rmse))